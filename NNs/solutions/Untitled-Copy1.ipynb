{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pden\n",
    "import pden.Net\n",
    "import pden.Operations\n",
    "import pden.PDENet\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport pden.Net\n",
    "%aimport pden.Operations\n",
    "%aimport pden.PDENet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def der(y, x, y_shape: int, x_shape: int):\n",
    "    ys = tf.split(y, [1] * y_shape, 1)\n",
    "    def _der(i, j=[]):\n",
    "        f = ys[i]\n",
    "        for _j in j:\n",
    "            fs = tf.gradients(f, x)[0]\n",
    "            f  = tf.split(fs, [1] * x_shape, 1)[_j]        \n",
    "        return f\n",
    "    return _der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net 1:\n",
      "\t23\tLinear: [2 -> 4]\n",
      "\t28\tActivation funciton: <function tanh at 0x12388fc20>\n",
      "\t6\tLinear: [4 -> 4]\n",
      "\t16\tActivation funciton: <function tanh at 0x12388fc20>\n",
      "\t18\tLinear: [4 -> 1]\n",
      "Net 16:\n",
      "\t16\tLinear: [2 -> 4]\n",
      "\t22\tActivation funciton: <function tanh at 0x12388fc20>\n",
      "\t32\tLinear: [4 -> 4]\n",
      "\t9\tActivation funciton: <function tanh at 0x12388fc20>\n",
      "\t30\tLinear: [4 -> 1]\n"
     ]
    }
   ],
   "source": [
    "net_u = pden.Net.BasicNet(\n",
    "    pden.Operations.Linear(feature_out=4, feature_in=2, random_init = True),\n",
    "    pden.Operations.ActivationFunction(tf.nn.tanh),\n",
    "    pden.Operations.Linear(feature_out=4, feature_in=4, random_init = True),\n",
    "    pden.Operations.ActivationFunction(tf.nn.tanh),\n",
    "    pden.Operations.Linear(feature_in=4, feature_out=1, random_init = True)\n",
    ")\n",
    "\n",
    "net_v = pden.Net.BasicNet(\n",
    "    pden.Operations.Linear(feature_out=4, feature_in=2, random_init = True),\n",
    "    pden.Operations.ActivationFunction(tf.nn.tanh),\n",
    "    pden.Operations.Linear(feature_out=4, feature_in=4, random_init = True),\n",
    "    pden.Operations.ActivationFunction(tf.nn.tanh),\n",
    "    pden.Operations.Linear(feature_in=4, feature_out=1, random_init = True)\n",
    ")\n",
    "\n",
    "pnet_u = pden.PDENet.PDENET(dimension_in=2, net=net_u)\n",
    "pnet_v = pden.PDENet.PDENET(dimension_in=2, net=net_v)\n",
    "\n",
    "print(net_u)\n",
    "print(net_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float64, [None, 2])\n",
    "_x, _y = tf.split(x, [1, 1], 1)\n",
    "u = pnet_u.forward(x)\n",
    "v = pnet_v.forward(x)\n",
    "\n",
    "bound_x_0 = tf.placeholder(tf.float64, [None, 2])\n",
    "bound_x_1 = tf.placeholder(tf.float64, [None, 2])\n",
    "bound_y_0 = tf.placeholder(tf.float64, [None, 2])\n",
    "bound_y_1 = tf.placeholder(tf.float64, [None, 2])\n",
    "\n",
    "bound_x_0_u = pnet_u.forward(bound_x_0)\n",
    "bound_x_1_u = pnet_u.forward(bound_x_1)\n",
    "bound_y_0_u = pnet_u.forward(bound_y_0)\n",
    "bound_y_1_u = pnet_u.forward(bound_y_1)\n",
    "\n",
    "bound_x_0_v = pnet_v.forward(bound_x_0)\n",
    "bound_x_1_v = pnet_v.forward(bound_x_1)\n",
    "bound_y_0_v = pnet_v.forward(bound_y_0)\n",
    "bound_y_1_v = pnet_v.forward(bound_y_1)\n",
    "\n",
    "ders_u = pnet_u.derivatives()\n",
    "ders_v = pnet_v.derivatives()\n",
    "\n",
    "du_dx = ders_u(0, j=[0])\n",
    "dv_dx = ders_v(0, j=[0])\n",
    "\n",
    "du_dy = ders_u(0, j=[1])\n",
    "dv_dy = ders_v(0, j=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u = sin(x) cos(y) \\\\\n",
    "v = cos(x) sin(y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnet_u = pnet_u.add_loss(tf.reduce_mean(tf.pow(du_dx + dv_dy - (2 * tf.cos(x[:, 0]) * tf.cos(x[:, 1])), 2)))\n",
    "pnet_u = pnet_u.add_loss(tf.reduce_mean(tf.pow(du_dy + dv_dx + (2 * tf.sin(x[:, 0]) * tf.sin(x[:, 1])), 2)), weight=1.0)\n",
    "pnet_u = pnet_u.add_loss(tf.reduce_mean(tf.pow(bound_x_0_u - 0.0, 2)), weight=3.0)\n",
    "pnet_u = pnet_u.add_loss(tf.reduce_mean(tf.pow(bound_y_0_v - 0.0, 2)), weight=3.0)\n",
    "\n",
    "pnet_v = pnet_v.add_loss(tf.reduce_mean(tf.pow(du_dx + dv_dy - (2 * tf.cos(x[:, 0]) * tf.cos(x[:, 1])), 2)))\n",
    "pnet_v = pnet_v.add_loss(tf.reduce_mean(tf.pow(du_dy + dv_dx + (2 * tf.sin(x[:, 0]) * tf.sin(x[:, 1])), 2)), weight=1.0)\n",
    "pnet_v = pnet_v.add_loss(tf.reduce_mean(tf.pow(bound_x_0_u - 0.0, 2)), weight=3.0)\n",
    "pnet_v = pnet_v.add_loss(tf.reduce_mean(tf.pow(bound_y_0_v - 0.0, 2)), weight=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4\n",
    "training_epochs = 25001\n",
    "display_step = 500\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train = opt.minimize(pnet_u.loss + pnet_v.loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "X = np.linspace(0, 1, n)\n",
    "\n",
    "_X, _Y = np.meshgrid(X, X)\n",
    "_XX = np.stack((_X.flatten(), _Y.flatten())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_0 = np.stack((X, np.zeros((n)))).T\n",
    "Y_1 = np.stack((X, np.ones((n)))).T\n",
    "X_0 = np.stack((np.zeros((n)), X)).T\n",
    "X_1 = np.stack((np.ones((n)), X)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error for net is \"0.572255639009138\". Epoch 25000\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "#     P = np.random.uniform(0, 0.5, size=(1,))\n",
    "    \n",
    "    _, l_u, l_v, U, V = sess.run([train, pnet_u.loss, pnet_v.loss, u, v], feed_dict={\n",
    "        x: _XX,\n",
    "        bound_x_0: X_0,\n",
    "        bound_x_1: X_1,\n",
    "        bound_y_0: Y_0,\n",
    "        bound_y_1: Y_1\n",
    "    })\n",
    "    \n",
    "    LOSS = np.mean( (U.reshape(n, n) - np.sin(_X) * np.cos(_Y)) ** 2 + (V.reshape(n, n) - np.sin(_Y) * np.cos(_X)) ** 2 )\n",
    "    \n",
    "    if epoch % display_step == 0:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        print(f'Training error for net is \"{LOSS}\". Epoch {epoch}')\n",
    "        \n",
    "\n",
    "        \n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
