\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Solving differential equations}{8}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Function approximation}{8}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Что-то про аппроксимацию и регуляризации в кратце}{8}{subsection.1.1.1}\protected@file@percent }
\newlabel{eq:linear_1d}{{1.1}{8}{Что-то про аппроксимацию и регуляризации в кратце}{equation.1.1.1}{}}
\newlabel{eq:linear_matrix_form}{{1.2}{9}{Что-то про аппроксимацию и регуляризации в кратце}{equation.1.1.2}{}}
\newlabel{eq:linear_expansion}{{1.3}{9}{Что-то про аппроксимацию и регуляризации в кратце}{equation.1.1.3}{}}
\newlabel{eq:loss}{{1.5}{9}{Что-то про аппроксимацию и регуляризации в кратце}{equation.1.1.5}{}}
\citation{kress2012numerical}
\citation{kress2012numerical}
\citation{ridge}
\citation{lasso}
\citation{dantzig_selector}
\citation{rlad}
\citation{slope}
\citation{haykin}
\citation{ridge}
\citation{lasso}
\citation{rlad}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Что то про линейную регрессию}{10}{subsection.1.1.2}\protected@file@percent }
\newlabel{eq:linear_opt}{{1.6}{10}{Что то про линейную регрессию}{equation.1.1.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Impact of the regularization}{10}{paragraph*.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Comparison of different regularizations}}{11}{figure.1.1}\protected@file@percent }
\newlabel{fig:regularizations}{{1.1}{11}{Comparison of different regularizations}{figure.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Expansion the functions into the functional series}{11}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Fourier series}{11}{subsection.1.2.1}\protected@file@percent }
\citation{fourierintro}
\@writefile{toc}{\contentsline {paragraph}{Example of function expansion into the Fourier series}{12}{paragraph*.5}\protected@file@percent }
\citation{fourierintro}
\citation{mason2002chebyshev}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Example of function expansion into the Fourier series with 3, 10, 18 terms}}{13}{figure.1.2}\protected@file@percent }
\newlabel{fig:fourier_demo}{{1.2}{13}{Example of function expansion into the Fourier series with 3, 10, 18 terms}{figure.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{The strong sides of Fourier expansion}{13}{subsubsection*.6}\protected@file@percent }
\newlabel{convergence-l2-norm}{{1.1}{13}{The strong sides of Fourier expansion}{theorem.1.1}{}}
\newlabel{convergence-pointwise}{{1.2}{13}{The strong sides of Fourier expansion}{theorem.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Chebyshev polynomials and series}{13}{subsection.1.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Illustration of the theorems \ref  {convergence-l2-norm}, \ref  {convergence-pointwise} for the function from the previous example}}{14}{figure.1.3}\protected@file@percent }
\newlabel{fig:fourier_quality}{{1.3}{14}{Illustration of the theorems \ref {convergence-l2-norm}, \ref {convergence-pointwise} for the function from the previous example}{figure.1.3}{}}
\newlabel{eq:chebyshev_series}{{1.11}{14}{Chebyshev polynomials and series}{equation.1.2.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Chebyshev polynomias for n = 3, 4, 5, 6}}{14}{figure.1.4}\protected@file@percent }
\newlabel{fig:chebyshev_demo}{{1.4}{14}{Chebyshev polynomias for n = 3, 4, 5, 6}{figure.1.4}{}}
\citation{mason2002chebyshev}
\citation{abramowitz1965handbook}
\newlabel{chevyshev_convergence}{{1.3}{15}{Chebyshev polynomials and series}{theorem.1.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Example of Chebyshev interpolation}{15}{paragraph*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Another functions and expansion over them}{15}{subsection.1.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Chebyshev expansion with 3, 4, 5, 6 terms }}{16}{figure.1.5}\protected@file@percent }
\newlabel{fig:chebyshev_expansion}{{1.5}{16}{Chebyshev expansion with 3, 4, 5, 6 terms}{figure.1.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{Function expansion over sigmoid function}{16}{subsubsection*.8}\protected@file@percent }
\newlabel{eq:sigmoidal_expansion}{{1.12}{16}{Function expansion over sigmoid function}{equation.1.2.12}{}}
\newlabel{sigmoidal_expansion}{{1.4}{17}{Function expansion over sigmoid function}{theorem.1.4}{}}
\citation{finlayson2013method}
\citation{fletcher2012computational}
\citation{gentle2007matrix}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Solving differentials equations}{18}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Introduction}{18}{subsection.1.3.1}\protected@file@percent }
\citation{fletcher2012computational}
\citation{dimov2019finite}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces The influence of the condition number on the solution accuracy}}{19}{figure.1.6}\protected@file@percent }
\newlabel{fig:ill_condition_demo}{{1.6}{19}{The influence of the condition number on the solution accuracy}{figure.1.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Solving Ordinary differential equations}{19}{subsection.1.3.2}\protected@file@percent }
\newlabel{eq:ode}{{1.13}{19}{Solving Ordinary differential equations}{equation.1.3.13}{}}
\citation{fletcher2012computational}
\@writefile{toc}{\contentsline {subsubsection}{Galerkin method}{20}{subsubsection*.9}\protected@file@percent }
\newlabel{eq:galerkin_presentation}{{1.14}{20}{Galerkin method}{equation.1.3.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{Galerkin method, special case}{21}{subsubsection*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Finite difference method}{21}{subsubsection*.11}\protected@file@percent }
\newlabel{eq:left_der}{{1.16}{21}{Finite difference method}{equation.1.3.16}{}}
\newlabel{eq:central_der}{{1.17}{21}{Finite difference method}{equation.1.3.17}{}}
\newlabel{eq:right_der}{{1.18}{21}{Finite difference method}{equation.1.3.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison of the provided methods}{22}{subsubsection*.12}\protected@file@percent }
\newlabel{eq:perceptron_ode}{{1.19}{22}{Comparison of the provided methods}{equation.1.3.19}{}}
\newlabel{eq:loss_galrekin}{{1.20}{22}{Comparison of the provided methods}{equation.1.3.20}{}}
\newlabel{eq:bad_system}{{1.21}{23}{Comparison of the provided methods}{equation.1.3.21}{}}
\newlabel{eq:good_system}{{1.22}{23}{Comparison of the provided methods}{equation.1.3.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{Artificial neural networks (ANN)}{23}{subsubsection*.13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces The illustration of \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:perceptron_ode}\unskip \@@italiccorr )}}. One layered neural network}}{23}{figure.1.7}\protected@file@percent }
\newlabel{fig:simple_net}{{1.7}{23}{The illustration of \eqref {eq:perceptron_ode}. One layered neural network}{figure.1.7}{}}
\citation{Adadelta}
\citation{Adagrad}
\citation{Adam}
\citation{Diffgrad}
\newlabel{eq:neural_net}{{1.23}{24}{Artificial neural networks (ANN)}{equation.1.3.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{Optimization part. Backpropagation algorithm}{24}{subsubsection*.14}\protected@file@percent }
\citation{chauvin2013backpropagation}
\@writefile{toc}{\contentsline {paragraph}{Optimizers comparison}{25}{paragraph*.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Comparison of different optimizers for fixed neural network architecture}}{25}{figure.1.8}\protected@file@percent }
\newlabel{fig:optimizers}{{1.8}{25}{Comparison of different optimizers for fixed neural network architecture}{figure.1.8}{}}
\citation{Lagaris_1998}
\citation{liu2019solving}
\citation{fletcher2012computational}
\newlabel{eq:simple_solver}{{1.25}{26}{Optimizers comparison}{equation.1.3.25}{}}
\@writefile{toc}{\contentsline {paragraph}{Example}{26}{paragraph*.16}\protected@file@percent }
\citation{cao2016locally}
\citation{Sirignano_2018}
\citation{Lagaris_1998}
\citation{liu2019solving}
\citation{cao2016locally}
\citation{Pun_2019}
\@writefile{toc}{\contentsline {subsubsection}{Examples of ODE}{27}{subsubsection*.17}\protected@file@percent }
\@setckpt{chapters/chapter2}{
\setcounter{page}{29}
\setcounter{equation}{25}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{10}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{3}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{8}
\setcounter{table}{0}
\setcounter{savepage}{3}
\setcounter{parentequation}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{10}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{11}
\setcounter{section@level}{0}
\setcounter{theorem}{4}
}
